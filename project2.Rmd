---
title: "R Notebook"
output: html_document
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r, include=FALSE}
library(portsort)
library(PerformanceAnalytics)
library(xts)
require(data.table)  # read in pandas-type data frame
require(dplyr)  # for syntax
require(feather) # to read in feather files
require(ggplot2) # for making pretty graphs
require(RcppRoll) # for creating lag/rolling
require(lubridate) # for manipulating dates
require(jtools)
#library(rlang)
library(stargazer)
#library(Hmisc)
library(pastecs)
library(psych)
library(scales)
library(BBmisc)
library(xtable)
library(pracma)
library(quantmod)
library(quantreg)
library(aTSA)

```


```{r}
# set scienfic notation to decimals
options(scipen = 999)
options(warn=-1)

options(xtable.floating = FALSE)
options(xtable.timestamp = "")

# ff data
df_rf <- read.csv('F-F_Research_Data_Factors_daily.CSV', skip=4)
df_rf$X = ymd(df_rf$X)
names(df_rf)[names(df_rf) == "X"] <- "Date"
df_rf <- subset(df_rf, Date >= as.Date('2011-1-1'))
df_rf <- subset(df_rf, Date <= as.Date('2018-05-31'))
```
# Read coin data
```{r}
# reading coin data
df = read.csv('consolidated_coin_data.csv')
df$Date = mdy(df$Date)
# set dt as datatable
setDT(df)

# reading btc data from coindesk
df_btc2 <- read.csv('coindesk-btc-price.csv')
df_btc2$Date = ymd(df_btc2$Date) 
names(df_btc2)[names(df_btc2) == "Price"] <- "Close"
df_btc <- df_btc2 %>% arrange(Date)
df_btc <- subset(df_btc, Date >= as.Date('2011-1-1'))
```

# Table a.1 shape of different currencies
```{r, results='asis'}
# table a.1 shape of different currencies
currencies2 = c('bitcoin')
#currencies2 = c('bitcoin', 'ripple', 'ethereum', 'binance-coin' ,'eos','tether', 'bitcoin-cash', 'stellar', 'litecoin', 'cardano')
plots = list()

for (j in 1:length(currencies2)){

  # if it is bitcoin, load coindesk data
  if (currencies2[j] == 'bitcoin'){
    df1 <- df_btc
  }else {
    df1 <- df%>% filter(Currency == currencies2[j])
  }

  # set date as key field
  df1= data.table(df1, key=c('Date'))
  
  # set upper range
  df1 <- subset(df1, Date <= as.Date('2018-5-31')) 
  
  # calculate daily ,weekly and monthly returns
  xts <- xts(df1$Close, df1$Date)
  dfd <- dailyReturn(xts, type='log')
  dfw <- weeklyReturn(xts, type='log')
  dfm <- monthlyReturn(xts, type='log')
  
  dfm <- data.frame(Date=index(dfm), coredata(dfm))
  setDT(dfm)
  
  # format output
  dfm[,Gains:=paste(round(monthly.returns*100,2), '%', sep="")]
  dfm[,Losses:=Gains]
  dfm$Month <- format(as.Date(dfm$Date), "%Y-%m")

  #setDT(dfm)
  
  # get top 10 gains
  top10 = dfm %>%  arrange(desc(monthly.returns)) %>% select(Month, Gains) %>% head(10)
  
  # get bottom 10 gains (top 10 losses)
  bottom10 = dfm %>%  arrange(monthly.returns) %>% select(Month, Losses) %>% head(10)
  
  # print the top gain and losses table
  top_gain_loss <- cbind(top10, bottom10)
  stargazer(top_gain_loss, type='text', summary=FALSE, title= paste(currencies2[j],'Top Gains and Losses'))
  
  dfd<-as.data.table(dfd)
  daily = as.data.frame(psych::describe(dfd$daily.returns))
  t <- dfd$daily.returns %>% t.test
  daily[['se']] = t$statistic[[1]]
  
  dfw<-as.data.table(dfw)
  weekly = as.data.frame(psych::describe(dfw$weekly.returns))
  t <- dfw$weekly.returns %>% t.test
  weekly[['se']] = t$statistic[[1]]

  dfm<-as.data.table(dfm)
  monthly = as.data.frame(psych::describe(dfm$monthly.returns))
  t <- dfm$monthly.returns %>% t.test
  monthly[['se']] = t$statistic[[1]]

  #merge results
  currency_summary <- rbind(daily, weekly, monthly)

  # format table
  setDT(currency_summary, keep.rownames = TRUE)
  currency_summary <- currency_summary[,list(Mean=paste0(round(mean*100,2),'%'), SD=paste0(round(sd*100,2),'%'), T_Stat=round(se,2), Skewness=round(skew,2), Kurtosis=round(kurtosis,2)), by=list(rn)]
  
  # formate index
  currency_summary[,1] <- c('Daily','Weekly','Monthly')

  # print results
  stargazer(currency_summary, type='text', summary=FALSE, title= paste(currencies2[j],'Log Return'))
}
```

# Table 14 - Calculate daily and weekly momentum for different currencies
```{r}
#currencies <- unique(df$Currency)
currencies2 = c('bitcoin')
#currencies2 = c('bitcoin', 'ripple', 'ethereum', 'binance-coin' ,'eos','tether', 'bitcoin-cash', 'stellar', 'litecoin', 'cardano')
#currencies3 = c('binance-coin' ,'eos','tether', 'bitcoin-cash', 'stellar', 'litecoin','ethereum', 'cardano')
plots = list()

for (j in 1:length(currencies2)){

  #df1 <- df%>% filter(Currency == 'ripple')
  if (currencies2[j] == 'bitcoin'){
    df1 <- df_btc
  }else {
    df1 <- df%>% filter(Currency == currencies2[j])
  }
  

  # set date as key field
  df1= data.table(df1, key=c('Date'))
  
  # set upper range
  df1 <- subset(df1, Date <= as.Date('2018-5-31')) 

  # create close price lag 1
  df1[, Close_lag1:=shift(Close, n=1, fill=NA, type='lag')]
  
  # return = (price of t/ price of t-1) -1
  df1[, plot_ret:= ((Close/Close_lag1)-1)]
  df1[, ret:= ((Close/Close_lag1)-1)]
  df1
  
  # Table 14, 18 - daily momentum
  # create lead and lag
  for (i in 1:7){
    df1[, paste('ret_lead',paste(i),sep=""):=shift(ret, n=i, fill = NA, type='lead')]
  }
  
  # generate formula
  model_results1 = list()
  for (i in 1:7){
    #f <- as.formula(paste('ret ~ ret_lead',paste(i), sep=""))
    #f <- as.formula(paste('(ret_lead',paste(i), '- rf_lead',paste(i) ,')~ ret', sep=""))
    f <- as.formula(paste('ret_lead',paste(i) ,'~ ret', sep=""))
    m = lm(f, data= df1)
    model_results1[[i]] = m
  }
  
  #print daily return
  stargazer(model_results1, header=F, type='text',
            title=paste(currencies2[j],'Daily Return (', paste(min(df1$Date)),'-',paste(max(df1$Date)),')'),
            omit.stat = c('LL','ser','f'),
            #t = list(NULL, sqrt(1)),
            covariate.labels =c('R(t)'),
            dep.var.labels=c('R(t+1)', 'R(t+2)', 'R(t+3)', 'R(t+4)','R(t+5)','R(t+6)', 'R(t+7)'),
            omit='Constant',
            report = 'vc*t')
  names(model_results1)
  
  # Table 14 -weekly momentum
  df1 <- mutate(day = wday(Date), .data= df1)
  df1 <- mutate(week = cut.Date(Date+1, breaks='1 week', label=FALSE),.data=df1)
  
  setDT(df1)
  df1[,Close_lead1w:=shift(Close, n=7, fill = NA, type='lead')]
  
  # set 1 week lag
  df1[,Close_lag1w:=shift(Close, n=7, fill = NA, type='lag')]
  
  df1[,weekly_ret:=((Close/Close_lag1w)-1)]
  print(paste(mean(df1$weekly_ret, na.rm=TRUE) ,sd(df1$weekly_ret, na.rm=TRUE)))
  
  setDT(df1)
  df1
  
  for (i in 1:7){
    df1[, paste('weekly_ret_lead',paste(i),sep=""):=shift(weekly_ret, n=i*7, fill = NA, type='lead')]
  }
  
  df2 <- df1 %>% filter(day == 1 | Date=='2018-5-31')
  setDT(df2)
  model_results = list()
  

  for (i in 1:4){
     #f <- as.formula(paste('ret ~ ret_lead',paste(i), sep=""))
     f <- as.formula(paste('weekly_ret_lead',paste(i), '~ weekly_ret', sep=""))
     m = lm(f, data= df2)
     model_results[[i]] = m
  }
  
  #print table 14
  stargazer(model_results, header=F, type='text',
            title=paste(currencies2[j],' Weekly Return (', paste(min(df1$Date)),'-',paste(max(df1$Date)),')'),
            omit.stat = c("LL","ser","f"),
            covariate.labels =c('R(t)'),
            dep.var.labels=c('R(t+1)', 'R(t+2)', 'R(t+3)', 'R(t+4)'),
            omit='Constant')
  
  
  if (currencies2[j] == 'bitcoin'){
    table26 <- df2
  }
  
}  


```




```{r, include=FALSE}
# define apply quantiles function, basically copy from last assignment
apply_quantiles=function(x,include_in_quantiles=NULL,bins=10){

          # if the argument is specified, we only include some data in hte calculate of breakpoints
          if(is.null(include_in_quantiles)) include_in_quantiles=rep(TRUE,length(x))
          # calculate quantiles (breakpoints)
          quantiles=quantile(ifelse(include_in_quantiles,x,NA),
                             probs=seq(0,1,length.out=bins+1),na.rm=TRUE)    
          quantiles['0%']=min(x,na.rm=TRUE)-1 ; quantiles['100%']=max(x,na.rm=TRUE)+1
          print(quantiles)
          # cut the data a bit more 
              #return(cut(x,breaks=quantiles,labels=FALSE))
          return(cut(x,breaks=quantiles,labels=FALSE))
}

# bitcoin_weekly <-table26
# bitcoin_weekly$bins <- apply_quantiles(bitcoin_weekly$weekly_ret, bins=5)
# 
# for (i in 1:4){
#    #f <- as.formula(paste('ret ~ ret_lead',paste(i), sep=""))
#    f <- as.formula(paste('weekly_ret_lead',paste(i), '~ weekly_ret', sep=""))
#    model = lm(f, data= bitcoin_weekly %>% filter(bins == 5))
#    sum <- summary(model)
#    print(i)
#    print(sum)
#    
# }
# # dfw %>% filter(bins == 5)
# # dfw %>% arrange(bins)
# # dfw %>% group_by(bins) %>% summarise(avg = n())
# # #dfw$bins2 <- cut(dfw$weekly_ret, breaks = c(-2, -0.0256, 0.0184, 0.0759, 0.27,2), labels = FALSE)
# #bitcoin_weekly %>% arrange(weekly_ret)
```

# Table 15 bitcoin returns by groups
```{r}
quant_summary = list()
cols = c('R(t+1)','R(t+2)','R(t+3)','R(t+4)')

#names(dfw)[names(dfw) == "weekly.returns"] <- "weekly_ret"
#names(dfw)[names(dfw) == "index"] <- "Date"

# bitcoin_weekly <- dfw
# for (i in 1:7){
#     bitcoin_weekly[, paste('weekly_ret_lead',paste(i),sep=""):=shift(weekly_ret, n=i, fill = NA, type='lead')]
# }

bitcoin_weekly <- table26
#dft$rank <- rank(dft$google_norm, ties.method = 'first')
#dft$bins <- apply_quantiles(dft$rank, bins=5)
#bitcoin_weekly[,weekly_ret:=standardize(weekly_ret)]
describe(bitcoin_weekly$weekly_ret)
bitcoin_weekly$bins <- apply_quantiles(bitcoin_weekly$weekly_ret, bins=5)

for (i in 1:5){
  for (j in 1:4){
   f <- as.formula(paste('weekly_ret_lead',paste(j), '~ weekly_ret', sep=""))
     model = lm(f, data= bitcoin_weekly %>% filter(bins == i))
     sum <- summary(model)
     sharpe = as.numeric(sum$coefficients[1,'Estimate'], na.rm=TRUE)/sd(model$model[,1])
     quant_summary[[j]] = c(sum$coefficients[1,], Sharpe=sharpe)
  }
  
  single_bin = data.frame(quant_summary)
  colnames(single_bin) <- cols
  #single_bin <- as.data.frame(t(as.matrix(single_bin)))
  setDT(single_bin,keep.rownames = TRUE)
  
  # add *** according to their p value
  for (k in 2:5){
    pvalue <- single_bin[,..k][4]
    coeff <- single_bin[,..k][1]
    if(pvalue < 0.01){
        #single_bin[1,2] <- paste0(round(coeff,2), '***')
    }
  }

  #names(single_bin) <- c('rn','Value','se', 't', 'pr', 'sd')
  
  stargazer(single_bin, #type='text',
            summary=FALSE, title=paste('Bitcoin Weekly Momentum by Groups - bin',i))
}
```


```{r, include=FALSE}
qs = c(0.2,0.4, 0.6, 0.8, 1)
qs = c(0, 0.2, 0.4, 0.6, 0.8)
quant_summary = list()
#kuantile(dfw$weekly_ret, probs = seq(0, 1, .2), na.rm = TRUE)

# bitcoin momentum by groups
for (i in 1:4){
   #f <- as.formula(paste('ret ~ ret_lead',paste(i), sep=""))
   f <- as.formula(paste('weekly_ret_lead',paste(i), '~ weekly_ret', sep=""))

   quantreg = rq(f, tau = qs, data= bitcoin_weekly)
   sum = summary(quantreg, se='boot')
   print(sum)
   #loop though 4 quantiles
   for (j in 1:5){
     # calculate the sd
     sd = as.numeric(sum[[j]]$coefficients[2,'Value'], na.rm=TRUE)/sd(quantreg$model$weekly_ret)
     as.numeric(sum[[j]]$coefficients[1,'Value'], na.rm=TRUE)
     quant_summary[[j]] = c(sum[[j]]$coefficients[1,], SD=sd)
   }
   
    #data.frame(c(sum[[j]]$coefficients[2,], sd=-1 ))

    report = data.frame(quant_summary)
    
    #print(report)
    # attach column names
    colnames(report) <- qs

    # transpose the df
    report <- as.data.frame(t(as.matrix(report)))
    setDT(report ,keep.rownames = TRUE)
    
    #display_names <- names(report)
    #display_names[[2]] = paste(paste('R(t)+'),i,sep="")
    names(report) <- c('rn','Value','se', 't', 'pr', 'sd')
    #report
    # round digits
    report[,Value:=Value*100, by=list(rn)]
    roundoff <- function(x) round(as.numeric(x),2)
    report[,2:length(names(report))] <- lapply(report[,2:length(names(report))],roundoff)
    
    # add *** to indicate confidence level
    report[, Value_s:= 
             ifelse(pr < 0.01,paste(paste(Value),'***',sep=""), 
                    ifelse(pr < 0.05,paste(paste(Value),'**',sep=""), 
                           ifelse(pr < 0.1,paste(paste(Value),'*',sep=""), paste(Value)))), by=list(rn)]
    
    report <- report[,list(Value_s,t,sd), by=list(rn)]
    names(report) <- c('Rank', paste(paste('R(t)+'),i,sep=""),'T-Stat','Sharpe Ratio' )
    print(xtable(report, summary=FALSE))
    report
    stargazer(report, type="text", main=paste('R(t)+',i,sep=""), summary=FALSE, rownames = FALSE)

}
```
# Import tweet data 
We are not able to retrieve the same data source of the tweet post count data as suggested in the paper as it is exclusive. Therefore, we retrieve the data from {} since {} to {} as the proxy to estimate social media sentiment
```{r}
# Tweet data
df_tweets <- read.csv('btc-tweets.csv')
setDT(df_tweets)

# set count as numeric
df_tweets[, Count:=as.numeric(Count)]

# parse date
df_tweets$Date = ymd(df_tweets$Date)

# set day number
df_tweets <- df_tweets %>% mutate(day = wday(Date, week_start = getOption("lubridate.week.start", 7)))

# set week number
df_tweets <- df_tweets %>% mutate(week = cut.Date(Date, breaks='1 week', label=FALSE))
#df_tweets <- df_tweets[, cum:=cumsum(Count)] %>% filter(day == 1)

# get only day 1 to extract weekly data
df_tweets <- df_tweets %>% group_by(week) %>% mutate(cum = cumsum(Count)) %>% filter(day == 1)
setDT(df_tweets)

# set lags
for (i in 1:4){
  df_tweets[, paste('cum_lag',paste(i),sep=''):= shift(cum, n=i, fill=NA, type='lag')]
  
}

# weekly average for t-1 to t-4
df_tweets[, avg:=sum(cum_lag1+cum_lag2+cum_lag3+cum_lag4,na.rm = TRUE)/4, by=list(Date)]


# calculate the tweet factor count(t) - average(count(t-1 to t-4))
df_tweets[, tweet:=(cum-avg), by=list(Date)]
setDT(df_tweets)

# standardize with mean 0 and sd 1 (suggested by the original report)
df_tweets[, tweet_norm:= standardize(tweet)]

# extract useful fields
df_tweets <- df_tweets[, list(Date, day, cum, avg, tweet_norm)]

qplot(data=df_tweets, x=Date, y=tweet_norm, geom = 'line')
# qplot(data=df2 %>% filter(Date >= as.Date('2014-01-01')), x=Date, y=weekly_ret, geom = 'line')
# min(df2$weekly_ret, na.rm=TRUE)
describe(df_tweets$tweet_norm)
```

```{r results='asis'}
# Table 26, 27 Bitcoin twitter
dft<-merge(bitcoin_weekly, df_tweets, by='Date')
quant_summary = list()
model_results3 = list()
#qs = c(0.17, 0.33, 0.5, 0.67, 0.83)
#qs = c(0,0.2, 0.4, 0.6, 0.8)
qs = c(0.2,0.4, 0.6, 0.8, 1)

 for(i in 1:7){
   #f <- as.formula(paste('ret ~ ret_lead',paste(i), sep=""))
   f <- as.formula(paste('weekly_ret_lead',paste(i), '~ tweet_norm', sep=""))
   #f <- as.formula(paste('weekly_ret_lead4 ~ tweet_norm', sep=""))
   
   m = lm(f, data= dft)
   model_results3[[i]] = m
}

stargazer(model_results3, type='text', header=F,
            title=paste('Bitcoin Weekly Return Twitter (', paste(min(dft$Date)),'-',paste(max(dft$Date)),')'),
            omit.stat = c("LL","ser","f"),
            covariate.labels =c('Twitter(t)'),
            dep.var.labels=c('R(t+1)', 'R(t+2)', 'R(t+3)', 'R(t+4)','R(t+5)','R(t+6)','R(t+7)'),
            omit='Constant',
            report = "vc*pt", flip=TRUE)
ggplot(dft, aes(x=Date)) + 
  geom_line(aes(y = dft$weekly_ret), color = "darkred") + 
  geom_line(aes(y = dft$tweet_norm), color="blue", linetype="twodash")


quantile(dft$tweet_norm)
```
# Tabble 27 Twitter by Groups
```{r results='asis'}
quant_summary = list()
cols = c('R(t+1)','R(t+2)','R(t+3)','R(t+4)')

#dft$rank <- rank(dft$google_norm, ties.method = 'first')
dft$bins <- apply_quantiles(dft$tweet_norm, bins=5)
for (i in 1:5){
  for (j in 1:4){
   f <- as.formula(paste('weekly_ret_lead',paste(j), '~ tweet_norm', sep=""))
     model = lm(f, data= dft %>% filter(bins == i))
     sum <- summary(model)
     sharpe = as.numeric(sum$coefficients[1,'Estimate'], na.rm=TRUE)/sd(model$model[,1])
     quant_summary[[j]] = c(sum$coefficients[1,], Sharpe=sharpe)
  }
  
  single_bin = data.frame(quant_summary)
  colnames(single_bin) <- cols
  #single_bin <- as.data.frame(t(as.matrix(single_bin)))
  setDT(single_bin,keep.rownames = TRUE)
  
  # add *** according to their p value
  for (k in 2:5){
    pvalue <- single_bin[,..k][4]
    coeff <- single_bin[,..k][1]
    # if(pvalue < 0.01){
    #   single_bin[,..k][1] <- paste0(round(coeff,2), '***')
    # }
  }

  #names(single_bin) <- c('rn','Value','se', 't', 'pr', 'sd')
  
  stargazer(single_bin,# type='text', 
            summary=FALSE, title=paste('Bitcoin Twitter by Groups - bin',i))
}
```


```{r results='asis', include=FALSE}
# table 27 tweet by quantiles
qs = c(0.2, 0.4, 0.6, 0.8,1)
for (i in 1:4){
   #f <- as.formula(paste('ret ~ ret_lead',paste(i), sep=""))
   f <- as.formula(paste('weekly_ret_lead',paste(i), '~ tweet_norm', sep=""))
   #f <- as.formula(paste('weekly_ret_lead4 ~ tweet_norm', sep=""))
   
   quantreg = rq(f, tau = qs, data= dft)
   sum = summary(quantreg, se='boot')
   
   #loop though 4 quantiles
   for (j in 1:5){
     # calculate the sd
     sd = as.numeric(sum[[j]]$coefficients[2,'Value'], na.rm=TRUE)/sd(quantreg$model$weekly_ret)
     quant_summary[[j]] = c(sum[[j]]$coefficients[1,], SD=sd)
   }
    #data.frame(c(sum[[j]]$coefficients[2,], sd=-1 ))
    # eval(paste0('quantreg$model$weekly_ret_lead',i))
    
    report = data.frame(quant_summary)
    #colnames(report)
    # attach column names
    colnames(report) <- qs

    # transpose the df
    report <- as.data.frame(t(as.matrix(report)))
    #colnames(report)
    setDT(report ,keep.rownames = TRUE)
    
    #display_names <- names(report)
    #display_names[[2]] = paste(paste('R(t)+'),i,sep="")
    names(report) <- c('rn','Value','se', 't', 'pr', 'sd')
    #report
    # round digits
    report[,Value:=Value*100, by=list(rn)]
    roundoff <- function(x) round(as.numeric(x),2)
    report[,2:length(names(report))] <- lapply(report[,2:length(names(report))],roundoff)
    
    # add *** to indicate confidence level
    report[, Value_s:= 
             ifelse(pr < 0.01,paste(paste(Value),'***',sep=""), 
                    ifelse(pr < 0.05,paste(paste(Value),'**',sep=""), 
                           ifelse(pr < 0.1,paste(paste(Value),'*',sep=""), paste(Value)))), by=list(rn)]
    
    report <- report[,list(Value_s,t,sd), by=list(rn)]
    names(report) <- c('Rank', paste(paste('R(t)+'),i,sep=""),'T-Stat','Sharpe Ratio' )
    print(xtable(report, summary=FALSE))
    #(report)
    stargazer(report, type="text", main=paste('R(t)+',i,sep=""), summary=FALSE, rownames = FALSE)

}


# stargazer(report, type='text', summary = FALSE)
# quantreg$model
# sum[[j]]$coefficients[2,4]
# stargazer(row, type='text')
# 

# setDT(dft)
# dft[,bins:=apply_quantiles(tweet_norm)]
#dft[, list(ret = mean(factor_norm)), by=list(bins)] %>% arrange(bins)
```
# Import bitcoin google search data
```{r}
df_google = read.csv('trends_bitcoin_weekly_Globe_full.csv')
df_google$Date = ymd(df_google$date)
df_google <- subset(df_google, Date >= as.Date('2011-1-1'))
df_google <- subset(df_google, Date <= as.Date('2018-12-31'))
df_google <- df_google %>% mutate(day = wday(Date, week_start = getOption("lubridate.week.start", 7)))
df_google <- df_google %>% mutate(week = cut.Date(Date, breaks='1 week', label=FALSE))
#df_tweets <- df_tweets[, cum:=cumsum(Count)] %>% filter(day == 1)
df_google <- df_google %>% group_by(week) %>% mutate(cum = cumsum(bitcoin)) %>% filter(day == 1)

setDT(df_google)


for (i in 1:4){
  df_google[, paste('cum_lag',paste(i),sep=''):= shift(bitcoin, n=i, fill=NA, type='lag')]
}
df_google <- df_google[, avg:=sum(cum_lag1+cum_lag2+cum_lag3+cum_lag4,na.rm = TRUE)/4, by=list(Date)]

# calculate the tweet factor count(t) - average(count(t-1 to t-4))
df_google <- df_google[, google:=cum-avg, by=list(Date)]
setDT(df_google)

# standardize to mean 0 and sd 1
df_google <- df_google[, google_norm:= standardize(google)]

# plot and describe
qplot(data=df_google, x=Date, y=google_norm,geom = 'line')
describe(df_google$google_norm)

```

# Table 18 - google search 2011-2018 weekly return momentum
```{r}

dft<-merge(bitcoin_weekly, df_google, by='Date')
quant_summary = list()
model_results4 = list()

for(i in 1:7){
   f <- as.formula(paste('weekly_ret_lead',paste(i), '~ google_norm', sep=""))
   m = lm(f, data= dft)
   model_results4[[i]] = m
}
#quantile(dft$google_norm)
stargazer(model_results4, header=F, type='text',
            title=paste('Google Search - Bitcoin (', paste(min(dft$Date)),'-',paste(max(dft$Date)),')'),
            omit.stat = c("LL","ser","f"),
            covariate.labels =c('Google(t)'),
            dep.var.labels=c('R(t+1)', 'R(t+2)', 'R(t+3)', 'R(t+4)','R(t+5)','R(t+6)','R(t+7)'),
            omit='Constant',
            report = "vc*pt", flip=TRUE)
ggplot(dft, aes(x=Date)) + 
  geom_line(aes(y = dft$weekly_ret), color = "darkred") + 
  geom_line(aes(y = dft$google_norm), color="blue", linetype="twodash")
  #geom_line(aes(y = dft$tweet_norm), color="green", linetype="twodash") 

```
# Table 20 Google by Groups
```{r }
quant_summary = list()
cols = c('R(t+1)','R(t+2)','R(t+3)','R(t+4)')

dft$rank <- rank(dft$google_norm, ties.method = 'first')
dft$bins <- apply_quantiles(dft$rank, bins=5)
for (i in 1:5){
  for (j in 1:4){
   f <- as.formula(paste('weekly_ret_lead',paste(j), '~ google_norm', sep=""))
     model = lm(f, data= dft %>% filter(bins == i))
     sum <- summary(model)
     sharpe = as.numeric(sum$coefficients[1,'Estimate'], na.rm=TRUE)/sd(model$model[,1])
     quant_summary[[j]] = c(sum$coefficients[1,], Sharpe=sharpe)
  }
  
  single_bin = data.frame(quant_summary)
  colnames(single_bin) <- cols
  #single_bin <- as.data.frame(t(as.matrix(single_bin)))
  setDT(single_bin,keep.rownames = TRUE)
  
  # add *** according to their p value
  for (k in 2:5){
    pvalue <- single_bin[,..k][4]
    coeff <- single_bin[,..k][1]
    # if(pvalue < 0.01){
    #   single_bin[,..k][1] <- paste0(round(coeff,2), '***')
    # }
  }

  #names(single_bin) <- c('rn','Value','se', 't', 'pr', 'sd')
  
  stargazer(single_bin, #type='text', 
            summary=FALSE, title=paste('Bitcoin Google Search by Groups - bin',i))
}

```

# Table 21 Google by Groups since 2013
```{r}
quant_summary = list()
cols = c('R(t+1)','R(t+2)','R(t+3)','R(t+4)')

dft$rank <- rank(dft$google_norm, ties.method = 'first')
dft$bins <- apply_quantiles(dft$rank, bins=5)
for (i in 1:5){
  for (j in 1:4){
   f <- as.formula(paste('weekly_ret_lead',paste(j), '~ google_norm', sep=""))
     model = lm(f, data= dft %>% filter(Date >= as.Date('2013-1-1')) %>% filter(bins == i))
     sum <- summary(model)
     sharpe = as.numeric(sum$coefficients[1,'Estimate'], na.rm=TRUE)/sd(model$model[,1])
     quant_summary[[j]] = c(sum$coefficients[1,], Sharpe=sharpe)
  }
  
  single_bin = data.frame(quant_summary)
  colnames(single_bin) <- cols
  #single_bin <- as.data.frame(t(as.matrix(single_bin)))
  setDT(single_bin,keep.rownames = TRUE)
  
  # add *** according to their p value
  for (k in 2:5){
    pvalue <- single_bin[,..k][4]
    coeff <- single_bin[,..k][1]
    # if(pvalue < 0.01){
    #   single_bin[,..k][1] <- paste0(round(coeff,2), '***')
    # }
  }

  #names(single_bin) <- c('rn','Value','se', 't', 'pr', 'sd')
  
  stargazer(single_bin, #type='text', 
            summary=FALSE, title=paste('Bitcoin Google Search by Groups (since 2013) - bin',i))
}
```

```{r, include=FALSE}
# since 2013
#df_google <- subset(df_google, Date >= as.Date('2013-1-1'))

#############################################################################################
# quant reg implementation
for (i in 1:4){
   #f <- as.formula(paste('ret ~ ret_lead',paste(i), sep=""))
   f <- as.formula(paste('weekly_ret_lead',paste(i), '~ google_norm', sep=""))
   #f <- as.formula(paste('weekly_ret_lead4 ~ tweet_norm', sep=""))
   
   quantreg = rq(f, tau = qs, data= dft)
   sum = summary(quantreg, se='boot')
   
   #loop though 4 quantiles
   for (j in 1:5){
     # calculate the sd
     sd = as.numeric(sum[[j]]$coefficients[2,'Value'], na.rm=TRUE)/sd(quantreg$model$weekly_ret)
     quant_summary[[j]] = c(sum[[j]]$coefficients[1,], SD=sd)
   }
    #data.frame(c(sum[[j]]$coefficients[2,], sd=-1 ))
    # eval(paste0('quantreg$model$weekly_ret_lead',i))
    
    report = data.frame(quant_summary)
    #colnames(report)
    # attach column names
    colnames(report) <- qs

    # transpose the df
    report <- as.data.frame(t(as.matrix(report)))
    #colnames(report)
    setDT(report ,keep.rownames = TRUE)
    
    #display_names <- names(report)
    #display_names[[2]] = paste(paste('R(t)+'),i,sep="")
    names(report) <- c('rn','Value','se', 't', 'pr', 'sd')
    #report
    # round digits
    report[,Value:=Value*100, by=list(rn)]
    roundoff <- function(x) round(as.numeric(x),2)
    report[,2:length(names(report))] <- lapply(report[,2:length(names(report))],roundoff)
    
    # add *** to indicate confidence level
    report[, Value_s:= 
             ifelse(pr < 0.01,paste(paste(Value),'***',sep=""), 
                    ifelse(pr < 0.05,paste(paste(Value),'**',sep=""), 
                           ifelse(pr < 0.1,paste(paste(Value),'*',sep=""), paste(Value)))), by=list(rn)]
    
    report <- report[,list(Value_s,t,sd), by=list(rn)]
    names(report) <- c('Rank', paste(paste('R(t)+'),i,sep=""),'T-Stat','Sharpe Ratio' )
    print(xtable(report, summary=FALSE))
    #(report)
    #stargazer(report, type="html", main=paste('R(t)+',i,sep=""), summary=FALSE, rownames = FALSE)

}

#dft[,bins,google_norm]
```

# Import bitcoin hack data
In this section, we follow the paper to construct the ratio of searches on bitcoin hack and bitcoin in the raw csv file
```{r}
df_google = read.csv('trends_bitcoin_hack_weekly_Globe_fullv2.csv')
df_google$Date = ymd(df_google$date)
df_google <- subset(df_google, Date >= as.Date('2011-1-1'))
df_google <- subset(df_google, Date <= as.Date('2018-12-31'))
df_google <- df_google %>% mutate(day = wday(Date, week_start = getOption("lubridate.week.start", 7)))
df_google <- df_google %>% mutate(week = cut.Date(Date, breaks='1 week', label=FALSE))
df_google <- df_google %>% group_by(week) %>% mutate(cum = cumsum(bitcoin)) %>% filter(day == 1)

setDT(df_google)

#df_google <- df_google[, google_norm:= BBmisc::normalize(bitcoin,method = "range", range=c(-1,1))]
df_google <- df_google[, google_norm:= standardize(bitcoin)]
qplot(data=df_google, x=Date, y=google_norm,geom = 'line')
describe(df_google$google_norm)
```
# Table {} - Bitcoin Hack
After running the regression, we also find very similar time-series momentum on the phrase bitcoin hack
```{r}
dft<-merge(bitcoin_weekly, df_google, by='Date')
quant_summary = list()
model_results4 = list()

for(i in 1:7){
   f <- as.formula(paste('weekly_ret_lead',paste(i), '~ google_norm', sep=""))
   m = lm(f, data= dft)
   model_results4[[i]] = m
}

stargazer(model_results4, header=F,#type='text',
            title=paste('Google Search - Bitcoin Hack to Bitcoin search (', paste(min(dft$Date)),'-',paste(max(dft$Date)),')'),
            omit.stat = c("LL","ser","f"),
            covariate.labels =c('Google(t)'),
            dep.var.labels=c('R(t+1)', 'R(t+2)', 'R(t+3)', 'R(t+4)','R(t+5)','R(t+6)','R(t+7)'),
            omit='Constant',
            report = "vc*pt", flip=TRUE)
# ggplot(dft, aes(x=Date)) + 
#   geom_line(aes(y = dft$weekly_ret), color = "darkred") + 
#   geom_line(aes(y = dft$google_norm), color="blue", linetype="twodash")
#   #geom_line(aes(y = dft$tweet_norm), color="green", linetype="twodash") 
```
# Table {} - Bitcoin hack by groups
```{r}
quant_summary = list()
cols = c('R(t+1)','R(t+2)','R(t+3)','R(t+4)')

#dft$rank <- rank(dft$google_norm, ties.method = 'first')
dft$bins <- apply_quantiles(dft$google_norm, bins=5)
for (i in 1:5){
  for (j in 1:4){
   f <- as.formula(paste('weekly_ret_lead',paste(j), '~ google_norm', sep=""))
     model = lm(f, data= dft %>% filter(bins == i))
     sum <- summary(model)
     sharpe = as.numeric(sum$coefficients[1,'Estimate'], na.rm=TRUE)/sd(model$model[,1])
     quant_summary[[j]] = c(sum$coefficients[1,], Sharpe=sharpe)
  }
  
  single_bin = data.frame(quant_summary)
  colnames(single_bin) <- cols
  #single_bin <- as.data.frame(t(as.matrix(single_bin)))
  setDT(single_bin,keep.rownames = TRUE)
  
  # add *** according to their p value
  for (k in 2:5){
    pvalue <- single_bin[,..k][4]
    coeff <- single_bin[,..k][1]
    # if(pvalue < 0.01){
    #   single_bin[,..k][1] <- paste0(round(coeff,2), '***')
    # }
  }

  #names(single_bin) <- c('rn','Value','se', 't', 'pr', 'sd')
  
  stargazer(single_bin, #type='text',
             summary=FALSE, title=paste('Bitcoin Hack by Groups - bin',i))
}

```

```{r, include=FALSE}
for (i in 1:4){
   #f <- as.formula(paste('ret ~ ret_lead',paste(i), sep=""))
   f <- as.formula(paste('weekly_ret_lead',paste(i), '~ google_norm', sep=""))
   #f <- as.formula(paste('weekly_ret_lead4 ~ tweet_norm', sep=""))
   
   quantreg = rq(f, tau = qs, data= dft)
   sum = summary(quantreg, se='boot')
   
   #loop though 4 quantiles
   for (j in 1:5){
     # calculate the sd
     sd = as.numeric(sum[[j]]$coefficients[2,'Value'], na.rm=TRUE)/sd(quantreg$model$weekly_ret)
     quant_summary[[j]] = c(sum[[j]]$coefficients[1,], SD=sd)
   }
    #data.frame(c(sum[[j]]$coefficients[2,], sd=-1 ))
    # eval(paste0('quantreg$model$weekly_ret_lead',i))
    
    report = data.frame(quant_summary)
    #colnames(report)
    # attach column names
    colnames(report) <- qs

    # transpose the df
    report <- as.data.frame(t(as.matrix(report)))
    #colnames(report)
    setDT(report ,keep.rownames = TRUE)
    
    #display_names <- names(report)
    #display_names[[2]] = paste(paste('R(t)+'),i,sep="")
    names(report) <- c('rn','Value','se', 't', 'pr', 'sd')
    #report
    # round digits
    report[,Value:=Value*100, by=list(rn)]
    roundoff <- function(x) round(as.numeric(x),2)
    report[,2:length(names(report))] <- lapply(report[,2:length(names(report))],roundoff)
    
    # add *** to indicate confidence level
    report[, Value_s:= 
             ifelse(pr < 0.01,paste(paste(Value),'***',sep=""), 
                    ifelse(pr < 0.05,paste(paste(Value),'**',sep=""), 
                           ifelse(pr < 0.1,paste(paste(Value),'*',sep=""), paste(Value)))), by=list(rn)]
    
    report <- report[,list(Value_s,t,sd), by=list(rn)]
    names(report) <- c('Rank', paste(paste('R(t)+'),i,sep=""),'T-Stat','Sharpe Ratio' )
    print(xtable(report, summary=FALSE))
    #(report)
    #stargazer(report, type="html", main=paste('R(t)+',i,sep=""), summary=FALSE, rownames = FALSE)

}

dft$bins <- apply_quantiles(dft$google_norm, bins=5)
for (i in 1:4){
   #f <- as.formula(paste('ret ~ ret_lead',paste(i), sep=""))

   f <- as.formula(paste('weekly_ret_lead',paste(i), '~ google_norm', sep=""))
   #f <- as.formula(paste('google_norm ~ weekly_ret_lead',paste(i), sep=""))
   model = lm(f, data= dft %>% filter(bins == 1))
   sum <- summary(model)
   print(i)
   print(sum)

}

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
